{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from pickle import load, dump\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from btk import rdx_sort\n",
    "\n",
    "plt.style.use(f\"{os.environ['style']}\")\n",
    "\n",
    "with open(r'D:\\dstore\\nlp\\w2v\\fwords', 'rt') as f:\n",
    "    full_words = Counter({f'_{x[1]}_': int(x[0]) for x in [x.strip().split() for x in f.readlines()]})\n",
    "\n",
    "for x in [x for x in full_words if len(x) < 5]:\n",
    "    full_words.pop(x)\n",
    "for x in [x for x in full_words if \"'\" in x]:\n",
    "    out = x.split(\"'\")\n",
    "    if f'{out[0]}_' in full_words:\n",
    "        full_words[f'{out[0]}_'] += full_words[x]\n",
    "    full_words.pop(x)\n",
    "\n",
    "ldct = {\n",
    "    'alpha': {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'},\n",
    "    '2afx': {\"_ab\", \"_ac\", \"_ad\", \"_af\", \"_ag\", \"_al\", \"_an\", \"_ap\", \"_ar\", \"_as\", \"_at\", \"_be\", \"_bi\", \"_by\", \"_co\", \"_de\", \"_di\", \"_ec\", \"_ef\", \"_el\", \"_em\", \"_en\", \"_ep\", \"_er\", \"_es\", \"_eu\", \"_ex\", \"_hi\", \"_ig\", \"_il\", \"_im\", \"_in\", \"_ir\", \"_ly\", \"_my\", \"_no\", \"_ob\", \"_oc\", \"_of\", \"_on\", \"_op\", \"_re\", \"_to\", \"_un\", \"_up\", \"ae_\", \"al_\", \"ar_\", \"by_\", \"cy_\", \"ea_\", \"ed_\", \"ee_\", \"el_\", \"en_\", \"er_\", \"es_\", \"et_\", \"ex_\", \"ia_\", \"ic_\", \"ie_\", \"in_\", \"is_\", \"la_\", \"ly_\", \"ol_\", \"or_\", \"ry_\", \"sa_\", \"sy_\", \"th_\", \"ty_\", \"um_\", \"up_\", \"yl_\"},\n",
    "    '1afx': {'s_', 'd_', 'r_', 'n_', 't_', 'y_', '_a', 'a_', '_o', 'o_', 'i_', '_e'},\n",
    "    'fdbl': {'b', 'c', 'd', 'f', 'g', 'l', 'm', 'n', 'p', 'r', 's', 't'},\n",
    "    'bdbl': {'b', 'd', 'g', 'm', 'l', 'n', 'p', 'r', 't'},\n",
    "    'avwls': {'a', 'e', 'i', 'o', 'u', 'y'},\n",
    "    'bvwls': {'a', 'e', 'i', 'o', 'u'},\n",
    "    'cvwls': {'a', 'e', 'o', 'i', 'y'},\n",
    "    'dvwls': {'a', 'e', 'o', 'u'},\n",
    "    'fvwls': {'a', 'o', 'i', 'u'},\n",
    "    'spafx': {'ity_', 'logy_', 'try_', 'sy_', 'cy_', 's_', 'y_'}\n",
    "}\n",
    "tpos = {\"_anti\", \"_arc\", \"_auto\", \"_bio\", \"_carbo\", \"_chroma\", \"_com\", \"_con\", \"_contra\", \"_counter\", \"_dis\", \"_fore\", \"_hyper\", \"_hypo\", \"_inter\", \"_iso\", \"_kin\", \"_lat\", \"_max\", \"_meta\", \"_micro\", \"_mis\", \"_mono\", \"_multi\", \"_neuro\", \"_non\", \"_ortho\", \"_over\", \"_para\", \"_photo\", \"_poly\", \"_pre\", \"_pro\", \"_pseudo\", \"_semi\", \"_sin\", \"_snow\", \"_sub\", \"_sum\", \"_sup\", \"_super\", \"_sym\", \"_trans\", \"_under\", \"_uni\", \"_var\", \"_vert\", \"_wolf\", \"able_\", \"ally_\", \"ate_\", \"fish_\", \"form_\", \"graph_\", \"ing_\", \"ish_\", \"ism_\", \"ist_\", \"ity_\", \"ive_\", \"ize_\", \"less_\", \"logy_\", \"man_\", \"ment_\", \"meter_\", \"ness_\", \"ory_\", \"ship_\", \"tone_\", \"try_\"}\n",
    "lockg = {*ldct['2afx'], *ldct['1afx'], *tpos}\n",
    "\n",
    "def get_nested(subject, stage, src):\n",
    "    hln = len(subject) * 3\n",
    "    hold = {x for x in src if subject in x and len(x) < hln}\n",
    "    if subject.strip('_') in hold:\n",
    "        hold.remove(subject.strip('_'))\n",
    "    return hold\n",
    "\n",
    "def extract_afx(subject, group, stage, src) -> list:\n",
    "    if stage == 1:\n",
    "        hold = []\n",
    "        group = [f'_{x}_'.split(subject) for x in group]\n",
    "        for x in group:\n",
    "            for y in x:\n",
    "                if len(y) > 2 or y in singles:\n",
    "                    hold.append(y)\n",
    "    return hold\n",
    "\n",
    "def afx_count(inp: Counter, stage: int):\n",
    "    hold = dict()\n",
    "    nons = []\n",
    "    if stage == 1:\n",
    "        src = inp\n",
    "    else:\n",
    "        src = {x.strip('_') for x in inp}\n",
    "    for subject in tqdm(inp):\n",
    "        out = get_nested(subject, stage, src)\n",
    "        if out:\n",
    "            hold[subject] = out\n",
    "        else:\n",
    "            nons.append(subject)\n",
    "    outp = Counter()\n",
    "    for subject in hold:\n",
    "        out = extract_afx(subject, hold[subject], stage, inp)\n",
    "        if out:\n",
    "            for x in out:\n",
    "                outp[x] += 1\n",
    "    return (Counter({x[0]: x[1] for x in outp.most_common() if x[1] > 2}), nons)\n",
    "\n",
    "def search(term, corpus, exc=None):\n",
    "    #Returns all items that contain the input affix \n",
    "    if not exc:\n",
    "        return sorted({x for x in corpus if term in x})\n",
    "    elif isinstance(exc, str):\n",
    "        return sorted({x for x in corpus if term in x and exc not in x})\n",
    "    else:\n",
    "        return sorted({x for x in corpus if term in x and all(y not in x for y in exc)})\n",
    "\n",
    "def gsub(target: str, afx: str, best=True, amode=0, guard=True, dbg=False):\n",
    "    #Remove the affix from a word following english rules, returning the proper root\n",
    "    if amode == 0:\n",
    "        if len(target) - len(afx) < 4: return\n",
    "    else:\n",
    "        if len(target) - len(afx) < 2: return\n",
    "    rep = target.replace(afx, '')\n",
    "    candidates = [target.replace(afx, '_')]\n",
    "    if afx[0] == '_':\n",
    "        pre = True\n",
    "    else:\n",
    "        pre = False\n",
    "    if not pre or amode in (1, 2):\n",
    "        if afx in ldct['spafx']:\n",
    "\n",
    "            if afx == 'logy_':\n",
    "                candidates.append(f'{rep}a_')\n",
    "                candidates.append(f'{rep}l_')\n",
    "                candidates.append(f'{rep[:-1]}_')\n",
    "                candidates.append(f'{rep[:-2]}_')\n",
    "            elif afx == 'ity_':\n",
    "                if rep.endswith('abil'):\n",
    "                    candidates.append(rep.replace('abil', 'able_'))\n",
    "                if rep.endswith('ibil'):\n",
    "                    candidates.append(rep.replace('ibil', 'ible_'))\n",
    "            elif afx == 'try_':\n",
    "                candidates.append(f'{rep}t_')\n",
    "            elif afx == 'cy_':\n",
    "                candidates.append(f'{rep}t_')\n",
    "                if rep[-1] == 'a': \n",
    "                    candidates.append(f'{rep}te_')\n",
    "            elif afx == 's_':\n",
    "                if rep[-1] in ['s', 'i', 'u']: return\n",
    "            elif afx == 'y_':\n",
    "                if rep[-1] in ldct['bvwls']: return\n",
    "\n",
    "        if dbg: print(candidates)\n",
    "        if afx[0] in ldct['bvwls']:\n",
    "            if afx[0] == rep[-1]:\n",
    "                return\n",
    "            dreps = [rep]\n",
    "            if len(rep) > 4 and rep[-1] == rep[-2] and rep[-1] in ldct['bdbl']:\n",
    "                dreps.append(rep[:-1])\n",
    "                candidates.append(f'{rep[:-1]}_')\n",
    "            elif rep[-1] in ldct['fvwls']:\n",
    "                candidates.append(f'{rep[:-1]}_')\n",
    "                candidates.append(f'{rep[:-1]}e_')\n",
    "                if rep[-1] == 'i':\n",
    "                    candidates.append(f'{rep[:-1]}y_')\n",
    "            for drep in dreps:\n",
    "                candidates.append(f'{drep}e_')\n",
    "                candidates.append(f'{drep}a_')\n",
    "                candidates.append(f'{drep}y_')\n",
    "                if afx[0] == 'e':\n",
    "                    if drep[-1] == 'v':\n",
    "                        candidates.append(f'{drep[:-1]}f_')\n",
    "                    if drep[-1] == 'm':\n",
    "                        candidates.append(f'{drep[:-1]}_')\n",
    "                elif afx[0] == 'i':\n",
    "                    if drep[-1] == 't':\n",
    "                        candidates.append(f'{drep[:-2]}e_')\n",
    "                        candidates.append(f'{drep[:-2]}_')\n",
    "                        if drep[-2] == 'i':\n",
    "                            candidates.append(f'{drep[:-1]}sh_')\n",
    "                        elif drep.endswith('ipt'):\n",
    "                            candidates.append(f'{drep[:-2]}be_')\n",
    "                        elif drep.endswith('orpt'):\n",
    "                            candidates.append(f'{drep[:-2]}b_')\n",
    "                    elif drep[-1] == 's':\n",
    "                        candidates.append(f'{drep[:-1]}e_')\n",
    "                        if drep[-2] in ldct['avwls']:\n",
    "                            candidates.append(f'{drep[:-1]}de_')\n",
    "                            candidates.append(f'{drep[:-1]}re_')\n",
    "                        elif drep[-2] == 's' and len(drep) > 2:\n",
    "                            if drep[-3] in ldct['dvwls']:\n",
    "                                candidates.append(f'{drep[:-2]}de_')\n",
    "                            elif drep[-3] == 'i':\n",
    "                                candidates.append(f'{drep[:-2]}t_')\n",
    "                        elif drep[-2] == 'r':\n",
    "                            candidates.append(f'{drep[:-1]}t_')\n",
    "                        elif drep[-2] == 'n':\n",
    "                            candidates.append(f'{drep[:-1]}d_')\n",
    "                elif afx[0] == 'a':\n",
    "                    if drep.endswith('ti'):\n",
    "                        candidates.append(f'{drep[:-2]}ce_')\n",
    "\n",
    "    if dbg: print(candidates)\n",
    "    if amode == 0: \n",
    "        out = sorted([(x, full_words[x]) for x in candidates if (x in full_words and full_words[x] > 4)], key=lambda x: x[1])\n",
    "    elif amode == 1:\n",
    "        out = sorted([(x, tf2[x]) for x in candidates if x in tf2], key=lambda x: x[1])\n",
    "    else:\n",
    "        out = []\n",
    "        if pre:\n",
    "            for x in candidates:\n",
    "                mafx = f'{x[1:]}_'\n",
    "                full = f'{x}_'\n",
    "                if mafx in tf2 and tf2[mafx] > 8:\n",
    "                    out.append((mafx, tf2[mafx]))\n",
    "                elif full in full_words and full_words[full] > 256:\n",
    "                    out.append((full, np.log2(full_words[full])))\n",
    "        else:\n",
    "            for x in candidates:\n",
    "                mafx = f'_{x[:-1]}'\n",
    "                full = f'_{x}'\n",
    "                if mafx in tf2 and tf2[mafx] > 8:\n",
    "                    out.append((mafx, tf2[mafx]))\n",
    "                elif full in full_words and full_words[full] > 256:\n",
    "                    out.append((full, np.log2(full_words[full])))\n",
    "        out = sorted(out, key=lambda x: x[1])\n",
    "    if out:\n",
    "        if best: return out[-1][0]\n",
    "        else: return out\n",
    "\n",
    "def target_removal(afx, exc1=None, exc2=None, exe=False, dbg=False):\n",
    "    #Find all affixes that contain the input affix and attempt to sub the affix. Only works if the replacement is in the affix list\n",
    "    if exc1 and exc2:\n",
    "        if isinstance(exc1, str) and isinstance(exc2, str):\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, exc1) and exc2 not in x]\n",
    "        elif isinstance(exc1, str):\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, exc1) and all(y not in x for y in exc2)]\n",
    "        elif isinstance(exc2, str):\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, *exc1) and exc2 not in x]\n",
    "        else:\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, *exc1) and all(y not in x for y in exc2)]\n",
    "    elif exc1:\n",
    "        if isinstance(exc1, str):\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, exc1)]\n",
    "        else:\n",
    "            targets = [x for x in tf2 if afx in x and x not in (afx, *exc1)]\n",
    "    elif exc2:\n",
    "        if isinstance(exc2, str):\n",
    "            targets = [x for x in tf2 if afx in x and x != afx and exc2 not in x]\n",
    "        else:\n",
    "            targets = [x for x in tf2 if afx in x and x != afx and all(y not in x for y in exc2)]\n",
    "    else:\n",
    "        targets = [x for x in tf2 if afx in x and x != afx]\n",
    "    rem = []\n",
    "    if dbg: print(targets)\n",
    "    for x in targets:\n",
    "        tmp = gsub(x, afx, amode=1)\n",
    "        if tmp: rem.append((x, tmp))\n",
    "    if exe:\n",
    "        for x in rem:\n",
    "            tf2[x[1]] += tf2[x[0]]\n",
    "            tf2.pop(x[0])\n",
    "    else: return rem\n",
    "\n",
    "def pulld(afx, len_lim=False):\n",
    "    #Return all child nodes of the input affix\n",
    "    aln = len(afx)\n",
    "    sub_set = [x for x in tf2 if afx in x]\n",
    "    out = []\n",
    "    for x in sub_set:\n",
    "        i = 1\n",
    "        if x[0] == '_':\n",
    "            while len(x[:-i]) > aln:\n",
    "                if x[:-i] in sub_set:\n",
    "                    break\n",
    "                i += 1\n",
    "            else:\n",
    "                out.append(x)\n",
    "        else:\n",
    "            while len(x[i:]) > aln:\n",
    "                if x[i:] in sub_set:\n",
    "                    break\n",
    "                i += 1\n",
    "            else:\n",
    "                out.append(x)\n",
    "    if not len_lim: return [x for x in out if x != afx]\n",
    "    else: return [x for x in out if len(x) == len(afx)+1 and x != afx]\n",
    "\n",
    "def pullu(afx):\n",
    "    #Return the parent node of the input affix\n",
    "    i = 1\n",
    "    if afx[0] == '_':\n",
    "        while i < len(afx):\n",
    "            if afx[:-i] in tf2:\n",
    "                return afx[:-i]\n",
    "            i += 1\n",
    "    else:\n",
    "        while i < len(afx):\n",
    "            if afx[i:] in tf2:\n",
    "                return afx[i:]\n",
    "            i += 1\n",
    "\n",
    "def chain(afx):\n",
    "    #Return the longest affix chain that contains the input affix\n",
    "    out = sorted([x for x in tf2 if afx in x or x in afx], key=lambda x: len(x))[-1]\n",
    "    return sorted([x for x in tf2 if x in out], key=lambda x: len(x), reverse=True)\n",
    "\n",
    "def pulld_relent(afx, depth=1):\n",
    "    #Grabs all that branch from input affix and their relative entropies.\n",
    "    #Returns the mean of those relative entropies\n",
    "    hold = [afx]\n",
    "    while depth > 0:\n",
    "        grp = []\n",
    "        while hold:\n",
    "            tmp = pulld(hold.pop(), True)\n",
    "            if tmp:\n",
    "                for y in tmp:\n",
    "                    grp.append(y)\n",
    "        hold.extend(grp)\n",
    "        depth -= 1\n",
    "    if hold:\n",
    "        hold = np.mean([drntp[x] for x in hold], axis=0)\n",
    "        return np.array([*[np.mean(x) for x in hold], *[np.mean(x) for x in hold.T]])\n",
    "    else: return np.array([0]*6)\n",
    "\n",
    "def remean(rearr):\n",
    "    return np.array([*[np.mean(y) for y in rearr], *[np.mean(y) for y in rearr.T]])\n",
    "\n",
    "def relent_peaks(target, bridge_coeff=1, dbg=False):\n",
    "    #Takes an affix and all affixes within its tree and compares their relative entropies.\n",
    "    #Returns affixes with significant peaks in relative entropies\n",
    "    scores = erw.copy()\n",
    "    words = chain(target)\n",
    "\n",
    "    for x in words: scores.append(rntp[x] * wgts)\n",
    "    if target[0] == '_': scores.append(frw)\n",
    "    else: scores.append(brw)\n",
    "    hold = zdre.copy()\n",
    "    for i in range(1, len(scores)-1): hold.append((scores[i+1]-scores[i])+(scores[i-1]-scores[i]))\n",
    "    if target[0] == '_': hold.extend([dfrw, dfrw])\n",
    "    else: hold.extend([dbrw, dbrw])\n",
    "\n",
    "    out = []\n",
    "    for i in range(2, len(hold)-2):\n",
    "        u1, d1, md = hold[i-1].copy(), hold[i+1].copy(), hold[i]\n",
    "        if dbg: print(words[i-2], (md-u1).mean(), (md-d1).mean())\n",
    "        if (md-u1).mean() > bridge_coeff or (md-d1).mean() > bridge_coeff:\n",
    "            u2, d2 = hold[i-2].copy(), hold[i+2].copy()\n",
    "            u2[u2 > u1] *= 0\n",
    "            u1[u1 > hold[i-2]] *= 0\n",
    "            d2[d2 > d1] *= 0\n",
    "            d1[d1 > hold[i+2]] *= 0\n",
    "            u1 = u1 + u2\n",
    "            d1 = d1 + d2\n",
    "        out.append((md-u1)+(md-d1))\n",
    "\n",
    "    if dbg:\n",
    "        for i, x in enumerate(out): print(words[i], '\\n', remean(x).mean(), '\\n', x)\n",
    "    return [(words[i], remean(x).mean()) for i, x in enumerate(out)]\n",
    "\n",
    "with open(r'D:\\dstore\\tmp\\4', 'rb') as f:\n",
    "    dsts = load(f)\n",
    "with open(r'D:\\dstore\\tmp\\5', 'rb') as f:\n",
    "    tf2, rntp, drntp = load(f)\n",
    "\n",
    "wgts = np.array([[1, 1, 1.25], [1, 1.25, 1.5], [1.25, 1.5, 1.75]])\n",
    "dsc = {x[0]: np.array([*[np.mean(y) for y in x[1]*wgts], *[np.mean(y) for y in x[1].T*wgts]]) for x in drntp.items()}\n",
    "frw, brw, erw = dsts['fr']*wgts, dsts['br']*wgts, [dsts['lr']*wgts]\n",
    "dfrw, dbrw = [], []\n",
    "for x in [x for x in tf2 if len(x) == 2 and x[0] == '_']: dfrw.append(rntp[x] - frw)\n",
    "for x in [x for x in tf2 if len(x) == 2 and x[-1] == '_']: dbrw.append(rntp[x] - brw)\n",
    "dfrw, dbrw = np.mean(dfrw, axis=0)*wgts, np.mean(dbrw, axis=0)*wgts\n",
    "zdre = [np.array([[0]*3]*3), np.array([[0]*3]*3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19617\n",
      " 72520.06479074272 1.0\n",
      "t 32784.12723658052 1.0\n",
      "tr 1571.1557322730284 1.0\n",
      "tra 555.9628893306825 1.0\n",
      "tran 109.53774787174389 1.0\n",
      "trans 94.27109140031605 4.128918794922771\n",
      "transf 26.666513738084316 4.68659835856655\n",
      "transfe 18.73594331447214 16.879033491359536\n",
      "transfer 18.701534383442933 368.02217464444107\n",
      "transferr 10.850384870265586 2941.6623846663606\n",
      "transferri 1.020849263393995 3590.2202681347812\n",
      "transferrin 1.020849263393995 7973.263292042616\n",
      "transferring 1.0 72520.06479074272\n"
     ]
    }
   ],
   "source": [
    "w = 'transferring'\n",
    "print(full_words[f'_{w}_'])\n",
    "for i in range(len(w)+1):\n",
    "    tally = 0\n",
    "    count = 0\n",
    "    for y in full_words:\n",
    "        if w[:i] in y:\n",
    "            tally += full_words[y]\n",
    "        if w[i:] in y:\n",
    "            count += full_words[y]\n",
    "    print(w[:i], tally/19617, count/19617)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tumbler(oafx):\n",
    "\n",
    "    if oafx[0] == '_': pre = True\n",
    "    else: pre = False\n",
    "    cnt = Counter()\n",
    "    afx = oafx.strip('_')\n",
    "    full_group = [x for x in tf2 if afx in x]\n",
    "    prefixes = [x.split(afx) for x in full_group if x[0] == '_']\n",
    "    suffixes = [x.split(afx) for x in full_group if x[-1] == '_']\n",
    "    if pre: \n",
    "        pre_pf = [x[0] for x in prefixes if x[0] and x[0] != '_' and len(x[0]) > 2 and x[0] in tf2 and tf2[x[0]] > 4]\n",
    "        suf_sf = [x[1] for x in suffixes if x[1] and x[1] != '_' and len(x[1]) > 4 and x[1] in tf2 and tf2[x[1]] > 4]\n",
    "        if len(oafx) < 4:\n",
    "            pre_sf = [f'_{x[1]}' for x in prefixes if len(x[1]) > 3 and f'_{x[1]}' in tf2]\n",
    "        else:\n",
    "            pre_sf = [y for y in [gsub(f'_{x[1]}', oafx, amode=True) for x in prefixes if x[1] and len(x[1]) > 3] if y and y in tf2]\n",
    "        for x in [*pre_pf, *pre_sf, *suf_sf]:\n",
    "            if x[0] == '_' and x[-1] == '_':\n",
    "                cnt[x] += int(full_words[x] ** (1/np.e))\n",
    "            else:\n",
    "                cnt[x] += tf2[x]\n",
    "        totals = (len(pre_pf), len(pre_sf), len(suf_sf), len(prefixes), len(suffixes), cnt.total(), len([x for x in cnt if x[0] == '_' and x[-1] == '_']))\n",
    "        return totals, cnt\n",
    "    else: \n",
    "        if len(oafx) < 4:\n",
    "            pre_pf = [x[0] for x in prefixes if x[0] and x[0] != '_' and len(x[0]) > 4 and x[0] in tf2]\n",
    "            suf_pf = [f'{x[0]}_' for x in suffixes if len(x[0]) > 2 and f'{x[0]}_' in tf2]\n",
    "        else:\n",
    "            pre_pf = [y for y in [gsub(x[0], oafx, amode=2) for x in prefixes if x[0] and x[0] != '_' and len(x[0]) > 4] if y]\n",
    "            suf_pf = [y for y in [gsub(f'_{x[0]}', oafx, amode=1) for x in suffixes if x[0] and len(x[0]) > 2] if y]\n",
    "        suf_sf = [x[1] for x in suffixes if x[1] and x[1] != '_' and len(x[1]) > 3 and x[1] in tf2 and tf2[x[1]] > 4]\n",
    "        for x in [*pre_pf, *suf_pf, *suf_sf]:\n",
    "            if x[0] == '_' and x[-1] == '_':\n",
    "                cnt[x] += int(full_words[x] ** (1/np.e))\n",
    "            else:\n",
    "                cnt[x] += tf2[x]\n",
    "        totals = (len(pre_pf), len(suf_pf), len(suf_sf), len(prefixes), len(suffixes), cnt.total(), len([x for x in cnt if x[0] == '_' and x[-1] == '_']))\n",
    "        return totals, cnt\n",
    "\n",
    "def grade(afx, grade=False, dbg=False):\n",
    "    # # of words with afx, # of words matched sans affix #of frags matched by removing affix from word\n",
    "    matches = search(afx, full_words)\n",
    "    reps = [x.replace(afx, '_') for x in matches if x.replace(afx, '_') in full_words]\n",
    "    rep_frags = [x.replace(afx, '') for x in matches if x.replace(afx, '') in tf2]\n",
    "    vals = [full_words[x] for x in reps]\n",
    "    frag_vals = [tf2[x] for x in rep_frags]\n",
    "    o1, o2, o3 = len(matches), len(reps), len(rep_frags)\n",
    "    if o2 > 0: o4 = np.mean(vals) + np.median(vals)/2\n",
    "    else: o4 = 1\n",
    "    if o3 > 0: o5 = np.mean(frag_vals) + np.median(frag_vals)/2\n",
    "    else: o5 = 1\n",
    "    if dbg:\n",
    "        for x in [x for x in zip(reps, vals)]: print(x)\n",
    "        for x in [x for x in zip(rep_frags, frag_vals)]: print(x)\n",
    "    if grade:\n",
    "        if o1 > 0 and o2 > 0: p1 = np.log2(o2/o1*o4) ** 2\n",
    "        else: p1 = 1\n",
    "        if o3 > 0 and o4 > 0: p2 = o3/o1*o5\n",
    "        else: p2 = 1\n",
    "        return round(p1 * p2, 4)\n",
    "    else: return o1, o2, o3, round(o4, 4), round(o5, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in [x for x in tf2 if len(x) > 9]:\n",
    "    tf2.pop(x)\n",
    "for x in ('less_', 'ness_'): target_removal(x, exe=True)\n",
    "target_removal('es_', exc1=('es_', 's_'), exc2=('is_', 'us_', 'ss_', 'series_', 'species_'), exe=True)\n",
    "target_removal('s_', exc1=('es_', 's_'), exc2=('is_', 'us_', 'ss_', 'series_', 'species_'), exe=True)\n",
    "target_removal('er_', exc2=('meter_', 'over_', 'under_', 'master_'), exe=True)\n",
    "target_removal('or_', exc2=('oor_'), exe=True)\n",
    "target_removal('ed_', exc2=('eed_'), exe=True)\n",
    "for x in ('en_', 'ly_', 'ion_', 'ous', 'ing_', 'ity_', 'ize_', 'ise_', 'ive_', 'ist_', 'ism_', 'ory_', 'est_', 'ment_', 'ant_', 'ary_', 'ate_', 'ic_', 'al_'):\n",
    "    target_removal(x, exe=True)\n",
    "target_removal('y_', exc2=('ity_', 'ry_', 'ly_', 'ory_', 'ary_'), exe=True)\n",
    "for x in [x[0] for x in tf2.most_common() if len(x[0]) < 5 and x[1] < 8]:\n",
    "    tf2.pop(x)\n",
    "for x in [x for x in tf2 if len(x) < 4 and x not in lockg]:\n",
    "    tf2.pop(x)\n",
    "\n",
    "ends = []\n",
    "for x in tf2:\n",
    "    if not pulld(x):\n",
    "        ends.append(x)\n",
    "scores = {x: [] for x in tf2}\n",
    "for x in ends:\n",
    "    for y in relent_peaks(x):\n",
    "        scores[y[0]].append(y[1])\n",
    "t = {x[0]: (np.mean(x[1]), np.median(x[1]), len([y for y in x[1] if y > 0.5]), len(x[1])) for x in scores.items()}\n",
    "for x in [x for x in t.items() if x[1][0] < -1.5 and x[1][2] / x[1][3] < 0.2 and x[0] not in lockg]:\n",
    "    tf2.pop(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2 = [*rdx_sort([x for x in tf2 if x[0] == '_']), *rdx_sort([x for x in tf2 if x[-1] == '_'])]\n",
    "fwords = rdx_sort(list(full_words))[::-1]\n",
    "rf2 = sorted(list({x.strip('_') for x in sf2 if len(x) > 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanmg = np.array([[255 if y in x else 0 for y in rf2] for x in fwords], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(scanmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2[18385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = []\n",
    "for x in sf2:\n",
    "    out = grade(x)\n",
    "    if out[3] == 1 and out[4] == 1:\n",
    "        rms.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_rep(afx):\n",
    "    u, v = 0, 0\n",
    "    group = search(afx, full_words)\n",
    "    for x in group:\n",
    "        x = x.replace(afx, '')\n",
    "        if len(x) > 3:\n",
    "            sub_group = [y for y in tf2 if x in y]\n",
    "            print(sub_group)\n",
    "            for y in sub_group:\n",
    "                u += 1\n",
    "                v += tf2[y]\n",
    "    print(afx, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afx = 'ive_'\n",
    "words = chain(afx)\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "yvars = [[*remean((rntp[w]*wgts)), *remean((drntp[w]*wgts))] for w in words]\n",
    "if afx[0] == '_': yvars.append([*remean((frw)), *remean((dfrw))])\n",
    "else: yvars.append([*remean((brw)), *remean((dbrw))])\n",
    "words.append('_')\n",
    "plt.xticks(range(len(yvars)), words)\n",
    "ax.plot(range(len(yvars)), yvars)\n",
    "ax.legend(['bidir', 'dir', 'xdir', 'win3', 'win2', 'win1', 'dbidir', 'ddir', 'dxdir', 'dwin3', 'dwin2', 'dwin1'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5fdee5dc54aebd0e437a010d5f0b24f3c36ee52e7479059de66cc5d4ada99b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
